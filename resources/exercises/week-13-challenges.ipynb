{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Statistics in Python\n",
    "\n",
    "I'm going to show you how to run some simple statistics using Python.\n",
    "\n",
    "In general, Python is very powerful for machine learning (e.g., scikit-learn, TensorFlow, etc.), while R is designed for statistics and cutting-edge statistical tools typically show up there first. That being said, all of the basic tools of a social science researcher are avaiable in Python.\n",
    "\n",
    "In this notebook, I show you how to run some basic statistical tests and models using the [scipy stats module](https://docs.scipy.org/doc/scipy/reference/stats.html). I am assuming that you already have a working knowledge of what these statistical tests do. I am just showing you how to perform them in Python.\n",
    "\n",
    "* Note: I personally do most of my statistical modeling in R, so I may be missing some of the tools that pure Python researchers would be aware of.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    "I'm going to just create some random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = stats.norm.rvs(size = 100) # 100 random, normally distributed values\n",
    "X2 = stats.norm.rvs(size = 100)\n",
    "X3 = stats.norm.rvs(size = 100)\n",
    "group = np.random.choice(['A','B','C'], size=100)\n",
    "# Our outcome is influenced by X1, X2, and the group, plus some random noise\n",
    "Y = 1.5 * X1 - 2.3 * X2 + 3 * (group == 'A') + 1.2 * (group == 'B') + stats.norm.rvs(size = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate statistics\n",
    "\n",
    "There are lots of univariate statistics we can get - mean, median, quartiles, quantiles, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.013540739077387403"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These all use numpy. This is the mean\n",
    "np.mean(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003303913596689736"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the median\n",
    "np.median(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.65504907, -0.00330391,  1.6066461 ])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantile takes an array and a list of the quantiles you want.\n",
    "# This shows the median and the quartiles\n",
    "np.quantile(X1, [.25, .5, .75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=100, minmax=(-1.8543308977911612, 2.2338785715595577), mean=-0.013540739077387403, variance=0.827555827924176, skewness=-0.017790983895410666, kurtosis=-0.559892463011074)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The describe function lists a number of these\n",
    "stats.describe(X1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-variate statistics\n",
    "\n",
    "### Correlations\n",
    "Scipy has both Pearson's coorelation and Spearman's rank correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.01997007490216445\n"
     ]
    }
   ],
   "source": [
    "# These 2 should not be correlated. \n",
    "stats.pearsonr(X1, X2)\n",
    "# the first value returned is R, the second is the p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=-0.01954995499549955, pvalue=0.8469119222123507)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4680999305382044, 9.062809332329399e-07)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These should be correlated, on the other hand\n",
    "stats.pearsonr(X1, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.453981398139814, pvalue=2.095768959903901e-06)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.spearmanr(X1, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-tests test whether 2 distributions have the same mean.\n",
    "\n",
    "# X1-X3 all should have the same mean, but Y should differ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.23595159929791404, pvalue=0.8137141160617511)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.3256364674048084, pvalue=2.409995406541033e-05)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(X3, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-squared test\n",
    "\n",
    "These test whether the frequency of something occurring by group is independent. So, we'll need to change Y into something that has a frequency.\n",
    "\n",
    "The following code will produce the 2 rows of a table. The first row (`large_y_counts`) is the number of large Y vaues by group. The second (`small_y_counts`) is the number of small y values per group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_y_counts = []\n",
    "small_y_counts = []\n",
    "Y_med = np.median(Y)\n",
    "for g in ['A','B','C']:\n",
    "    large_y_count = 0\n",
    "    small_y_count = 0\n",
    "    # Instead of looping through the values, we loop through the index.\n",
    "    # That way we can also get the index of the `groups` variable\n",
    "    for i in range(len(Y)):\n",
    "        if group[i] == g:\n",
    "            if Y[i] > Y_med:\n",
    "                large_y_count += 1\n",
    "            else:\n",
    "                small_y_count += 1\n",
    "    large_y_counts.append(large_y_count)\n",
    "    small_y_counts.append(small_y_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20.359447004608295, 3.793169550735125e-05, 2, array([[15.5, 21. , 13.5],\n",
       "        [15.5, 21. , 13.5]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we call the Chi-squared test\n",
    "stats.chi2_contingency(np.array([large_y_counts, small_y_counts]))\n",
    "# This returns the Chi-square value, a p-value, degrees of freedom, and the expected counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA\n",
    "\n",
    "This tests whether the means of multiple groups have the same population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=0.20072298916835568, pvalue=0.8182499263023821)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these all should\n",
    "stats.f_oneway(X1,X2,X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=15.33062583228185, pvalue=1.8662451407414083e-09)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# but adding Y should change it\n",
    "\n",
    "stats.f_oneway(X1,X2,X3,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=1.8108511287523748, intercept=1.552793497695232, rvalue=0.46809993053820487, pvalue=9.0628093323292e-07, stderr=0.34532177628953775)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple linear regression is possible with scipy stats\n",
    "stats.linregress(X1, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but for multiple regression we need to use something else. One option is sklearn,\n",
    "# the machine learning package. Another, maybe simpler is statsmodels, which I show here:\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'X1':X1,\n",
    "                   'X2':X2,\n",
    "                   'X3': X3,\n",
    "                   'group':group,\n",
    "                   'Y':Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sm.ols(formula=\"Y ~ X1 + X2 + X3 + group\", data=df).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>Y</td>        <th>  R-squared:         </th> <td>   0.924</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   229.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 13 Apr 2020</td> <th>  Prob (F-statistic):</th> <td>4.89e-51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:04:58</td>     <th>  Log-Likelihood:    </th> <td> -138.22</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   100</td>      <th>  AIC:               </th> <td>   288.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    94</td>      <th>  BIC:               </th> <td>   304.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    3.1605</td> <td>    0.180</td> <td>   17.557</td> <td> 0.000</td> <td>    2.803</td> <td>    3.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group[T.B]</th> <td>   -1.7978</td> <td>    0.238</td> <td>   -7.564</td> <td> 0.000</td> <td>   -2.270</td> <td>   -1.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>group[T.C]</th> <td>   -3.0180</td> <td>    0.264</td> <td>  -11.431</td> <td> 0.000</td> <td>   -3.542</td> <td>   -2.494</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X1</th>         <td>    1.5869</td> <td>    0.111</td> <td>   14.293</td> <td> 0.000</td> <td>    1.366</td> <td>    1.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X2</th>         <td>   -2.4333</td> <td>    0.092</td> <td>  -26.431</td> <td> 0.000</td> <td>   -2.616</td> <td>   -2.250</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>X3</th>         <td>   -0.1049</td> <td>    0.088</td> <td>   -1.196</td> <td> 0.235</td> <td>   -0.279</td> <td>    0.069</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.760</td> <th>  Durbin-Watson:     </th> <td>   2.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.093</td> <th>  Jarque-Bera (JB):  </th> <td>   4.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.518</td> <th>  Prob(JB):          </th> <td>   0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.043</td> <th>  Cond. No.          </th> <td>    4.10</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      Y   R-squared:                       0.924\n",
       "Model:                            OLS   Adj. R-squared:                  0.920\n",
       "Method:                 Least Squares   F-statistic:                     229.3\n",
       "Date:                Mon, 13 Apr 2020   Prob (F-statistic):           4.89e-51\n",
       "Time:                        17:04:58   Log-Likelihood:                -138.22\n",
       "No. Observations:                 100   AIC:                             288.4\n",
       "Df Residuals:                      94   BIC:                             304.1\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      3.1605      0.180     17.557      0.000       2.803       3.518\n",
       "group[T.B]    -1.7978      0.238     -7.564      0.000      -2.270      -1.326\n",
       "group[T.C]    -3.0180      0.264    -11.431      0.000      -3.542      -2.494\n",
       "X1             1.5869      0.111     14.293      0.000       1.366       1.807\n",
       "X2            -2.4333      0.092    -26.431      0.000      -2.616      -2.250\n",
       "X3            -0.1049      0.088     -1.196      0.235      -0.279       0.069\n",
       "==============================================================================\n",
       "Omnibus:                        4.760   Durbin-Watson:                   2.380\n",
       "Prob(Omnibus):                  0.093   Jarque-Bera (JB):                4.472\n",
       "Skew:                           0.518   Prob(JB):                        0.107\n",
       "Kurtosis:                       3.043   Cond. No.                         4.10\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the benefit of regression - the coefficient for X1 is much closer to the true coefficient (1.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
